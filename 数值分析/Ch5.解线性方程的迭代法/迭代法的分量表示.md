# Jacobi 迭代法

Jacobi 迭代法其实源于这种：
$$\begin{cases}
a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n=b_1\\
a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n=b_2\\
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\vdots\\
a_{n1}x_1+a_{n2}x_2+\cdots+a_{nn}x_n=b_n\\
\end{cases}\to\begin{cases}
x_1=({b_1-a_{12}x_2-\cdots-a_{1n}x_n})/{a_{11}}\\
x_2=({b_2-a_{21}x_1-\cdots-a_{2n}x_n})/{a_{22}}\\
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\vdots\\
x_n=({b_n-a_{n1}x_1-\cdots-a_{n,n-1}x_{n-1}})/{a_{nn}}\\
\end{cases}
$$
其核心在于其变量的确立为依赖于其他变量，有点类似与“整体”迭代的感觉，换做迭代写法就是：
$$\begin{cases}
x^{(0)}=[x_1^{(0)},x_2^{(0)},\cdots,x_n^{(0)}]\\
x_{i}^{(k+1)}=(b_i-\sum^{n}_{j=1,j\ne i}a_{ij}x_{j}^{(k)})/a_{ii}\\
i是分量序号，k是迭代次数
\end{cases}$$
# Gauss-Seidel 迭代法

Gauss-Seidel 源于这种思想，即，如果 Jacobi 迭代法迭代结果是逐渐趋近于真正的收敛结果，那么就会有：$x_{i+1}^{(k)}$ 的精度比 $x_{i}^{(k)}$ 更高，那么在同一次迭代过程中，为什么不用精度更高的而是选用精度更低的呢。
基于此，会有其迭代方程：
$$\begin{cases}
x^{(0)}=[x_1^{(0)},x_2^{(0)},\cdots,x_n^{(0)}]\\
x_{i}^{(k+1)}=(b_i-\sum^{i-1}_{j=1}a_{ij}x_{j}^{(k+1)}-\sum^{n}_{j=i+1}a_{ij}x_{j}^{(k)})/a_{ii}\\
i是分量序号，k是迭代次数
\end{cases}$$
# SOR 迭代法

Successive Over-Relaxation

$x_{i+1}^{(k)}$ 与 $x_{i}^{(k)}$ 是迭代中的一个分量在不同迭代中的结果，那么根据数值分析的一个核心算法思想，也就是松弛法，也可以通过组合得到相应的迭代松弛法，但是一般的松弛法都是对于一个分量加减 $\triangle x$ 进行操作的，因此与前面不相同，这里的写法参照：
$$x_i^{(k+1)}=x_i^{(k)}+\triangle x_i$$
对 Gauss-Seidel 迭代法进行操作，以便后续推广，那么就有：
$$x_i^{(k+1)}=(1-\omega)x_i^{(k)}+\omega((b_i-\sum^{i-1}_{j=1}a_{ij}x_{j}^{(k+1)}-\sum^{n}_{j=i+1}a_{ij}x_{j}^{(k)})/a_{ii}$$
其中 $\omega$ 为松弛因子，当为1的时候，也就是 Gauss-Seidel 算法
[[线性方程迭代法]]